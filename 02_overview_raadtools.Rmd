---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Overview 

```{r preamble, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(raadtools)
```


What is required for a domain-specific toolkit? 

* where is the data?
* where are the files? 
* are the files up to date? 
* how do I read the data? 
* how do I map the data?
* how do I integrate the data with my data? 




This session will first present a way of working with a data library that we have developed. I'll show some examples of reading remote sensing data, comparing it with a global topographic data set. In the next section we will all create that toolkit and use it with these two data sets. Our data library includes dozens of other types of data sources, but it's too much to replicate in a short session. 

We tend to see these three tasks done by a researcher all mixed together. 

Get Files. 

Index Files. 

Read Files. 



## Get Files

Download files for a collection. 

Specify file type, pattern. 

We need a download method, check local copy for updates at source, unzip after download. 

Download method may be http, ftp, require login, or special queries. 


## Index Files

Listing files is best done regularly, it takes time so should be cached. 

List all files in the library, keep a copy of the list, search the list for targets. 

File names can change, directory structure can change, so search needs to be general or easily updateable. 

## Read Files

So many formats!  

GDAL, rgdal, sf, raster, stars, NetCDF, GeoTIFF, raw binary, text files





# A preview with raadtools 

This code relies on having run the set up in [setup link 00_getting_set_up](). 


```{r setup-workshop, eval=FALSE}
library(raadtools)
my_data_dir <- file.path(tempdir(), "datalibrary")
set_data_roots(my_data_dir)
```

Our data toolkit is a growing collection of *known datasets*. Most can be read by raster or stars, but many have specific
details that aren't easily understood by generic tools. 

```{r ice}
readice(latest = TRUE)  ## a map projection

readsst("2002-01-01")   ## longlat regular 

readcurr("2003-01-02", xylim = extent(100, 120, -40, -30))  ## two variables


```

# Where is the data?

Nice if we have a single location for a shared data library, configurable and available to different systems (Linux, Windows, Mac, servers, desktop). 

# Where are the files and are they up to date?

An index of available file names is useful before we even access any data. 

* time coverage
* type of data

This file listing provides an immediate check of suitability, maybe I need last week's data but only up to a month ago is available. 

Or perhaps only started in 2002 (and I need 1990). 

# How to read the data? 

We have standard read tools in raster, stars, rgdal, ncdf4, RNetCDF, rhdf5 ... but do they know about particular details and vagaries? 

* Is time included, is georeferencing correct, are these static variables or paired vector components, a continuous or discrete quantity? 

Plotting, mapping, projections, extractions, aggregating, ...


